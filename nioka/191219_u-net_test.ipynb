{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "191219 U-netの勉強"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unet_with_fine_tuning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/killthekitten/kaggle-carvana-2017/blob/master/models.py\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.engine.topology import Input\n",
    "from keras.engine.training import Model\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.core import Activation, SpatialDropout2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from inception_resnet_v2 import InceptionResNetV2\n",
    "from mobile_net_fixed import MobileNet\n",
    "from resnet50_fixed import ResNet50\n",
    "# from param import args\n",
    "\n",
    "import Unet_with_fine_tuning_models\n",
    "import losses\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "from skimage.transform import rescale\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "# from skimage.util.montage import montage2d as montage\n",
    "from skimage.morphology import binary_opening, disk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.morphology import label\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models, layers\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import ImageFile,Image\n",
    "import losses\n",
    "import gc; gc.enable()\n",
    "\n",
    "image_rgb_dir = \"./Original_image/nerve_split/\"\n",
    "image_mask_dir = \"./Binary_image/nerve_split/\"\n",
    "\n",
    "input_shape = (256,256,1)\n",
    "\n",
    "train_list = glob(\"./Original_image/nerve_split/*.bmp\")\n",
    "tmp=[]\n",
    "for id in train_list:\n",
    "    tmp.append(id.split('/')[-1])\n",
    "    # print(id)\n",
    "\n",
    "train_list=tmp\n",
    "train_list, valid_list = train_test_split(train_list,test_size=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"         Decode RLEs into Images         \"\"\"\n",
    "\n",
    "\n",
    "def make_image_gen(in_list, batch_size):\n",
    "    all_batches = in_list\n",
    "    out_rgb = []\n",
    "    out_mask = []\n",
    "    while True:\n",
    "        np.random.shuffle(all_batches)\n",
    "        for c_img_id in all_batches:\n",
    "            rgb_path = image_rgb_dir+c_img_id\n",
    "            c_img = imread(rgb_path)\n",
    "            c_img = np.reshape(c_img,(c_img.shape[0],c_img.shape[1],1))\n",
    "            rgb_path=rgb_path.split('/')[-1]\n",
    "            name, ext = os.path.splitext(rgb_path)\n",
    "            mask_path = image_mask_dir+name+'_mask'+ext\n",
    "            # print(mask_path)\n",
    "            c_mask = imread(mask_path)\n",
    "            c_mask = np.reshape(c_mask,(c_mask.shape[0],c_mask.shape[1],1))\n",
    "            out_rgb += [c_img]\n",
    "            out_mask += [c_mask]\n",
    "            if len(out_rgb)>=batch_size:\n",
    "                yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0)/255.0\n",
    "                out_rgb, out_mask=[], []\n",
    "\n",
    "\"\"\"         Augmentation            \"\"\"\n",
    "\n",
    "\n",
    "dg_args = dict(featurewise_center = False,\n",
    "               samplewise_center = False,\n",
    "               rotation_range = 45,\n",
    "               width_shift_range = 0.1,\n",
    "               height_shift_range = 0.1,\n",
    "               shear_range = 0.01,\n",
    "               zoom_range = [0.9, 1.1],\n",
    "               horizontal_flip = True,\n",
    "               vertical_flip = True,\n",
    "               fill_mode = 'reflect',\n",
    "               data_format = 'channels_last')\n",
    "\n",
    "image_gen = ImageDataGenerator(**dg_args)\n",
    "label_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "\n",
    "def create_aug_gen(in_gen, seed = None):\n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    for in_x, in_y in in_gen:\n",
    "        seed = np.random.choice(range(9999))\n",
    "        # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n",
    "        g_x = image_gen.flow(255*in_x,\n",
    "                             batch_size = in_x.shape[0],\n",
    "                             seed = seed,\n",
    "                             shuffle=True)\n",
    "        g_y = label_gen.flow(in_y,\n",
    "                             batch_size = in_x.shape[0],\n",
    "                             seed = seed,\n",
    "                             shuffle=True)\n",
    "\n",
    "        yield next(g_x)/255.0, next(g_y)\n",
    "\n",
    "\n",
    "# t_x, t_y = next(create_aug_gen(train_gen))\n",
    "gc.collect()\n",
    "\n",
    "\"\"\"         Build a Model           \"\"\"\n",
    "\n",
    "\n",
    "make_model = Unet_with_fine_tuning_models\n",
    "model_name = 'simple_unet'     # resnet50, inception_resnet_v2, mobilenet, vgg, simple_unet\n",
    "model = make_model.chose_model(input_shape,model_name)\n",
    "\n",
    "make_loss = losses\n",
    "model.compile(optimizer=Adam(1e-3, decay=1e-6), loss=make_loss.dice_coef_loss, metrics=['accuracy', make_loss.dice_coef])\n",
    "\n",
    "weight_path=\"{}_weights.best.hdf5\".format('seg_model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min',\n",
    "                             save_weights_only=True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                   patience=1, verbose=1, mode='min',\n",
    "                                   epsilon=0.0001, cooldown=2, min_lr=1e-7)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=2,\n",
    "                      patience=20) # probably needs to be more patient, but kaggle time is limited\n",
    "\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n",
    "\n",
    "# callbacks_list = [checkpoint, reduceLROnPlat]\n",
    "\n",
    "\n",
    "\n",
    "valid_x, valid_y = next(make_image_gen(valid_list,batch_size=len(valid_list)))\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# maximum number of steps_per_epoch in training\n",
    "MAX_TRAIN_STEPS = 7\n",
    "MAX_TRAIN_EPOCHS = 99\n",
    "\n",
    "epoch = min(MAX_TRAIN_STEPS, len(train_list)//BATCH_SIZE)\n",
    "aug_gen = create_aug_gen(make_image_gen(train_list,BATCH_SIZE))\n",
    "loss_history = [model.fit_generator(aug_gen,\n",
    "                                    steps_per_epoch=epoch,\n",
    "                                    epochs=MAX_TRAIN_EPOCHS,\n",
    "                                    validation_data=(valid_x, valid_y),\n",
    "                                    callbacks=callbacks_list,\n",
    "                                    # workers=1 # the generator is not very thread safe\n",
    "                                    verbose=1\n",
    "                                   )]\n",
    "\n",
    "\n",
    "def save_loss(loss_history):\n",
    "    epich = np.cumsum(np.concatenate(\n",
    "        [np.linspace(0.5, 1, len(mh.epoch)) for mh in loss_history]))\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 10))\n",
    "    _ = ax1.plot(epich,\n",
    "                 np.concatenate([mh.history['loss'] for mh in loss_history]),\n",
    "                 'b-',\n",
    "                 epich, np.concatenate(\n",
    "            [mh.history['val_loss'] for mh in loss_history]), 'r-')\n",
    "    ax1.legend(['Training', 'Validation'])\n",
    "    ax1.set_title('Loss')\n",
    "\n",
    "    fig.savefig('result.png')\n",
    "\n",
    "\n",
    "save_loss(loss_history)\n",
    "\n",
    "model.load_weights(weight_path)\n",
    "model.save('model_unet_with_'+model_name+'.h5')\n",
    "\n",
    "\n",
    "\n",
    "##############################################\n",
    "#               predict\n",
    "##############################################\n",
    "\n",
    "img_list = glob(\"./Original_image/nerve_split/*.bmp\")\n",
    "for img_id in img_list:\n",
    "    img = imread(img_id)\n",
    "    img=np.reshape(img,(input_shape[0],input_shape[1],1)).astype(np.float)\n",
    "    img/=255.\n",
    "    img=np.expand_dims(img,axis=0)\n",
    "    img_mask=model.predict(img)\n",
    "    # print(img_mask.shape)\n",
    "    img_mask*=255.0\n",
    "    img_mask=np.reshape(img_mask,(input_shape[0],input_shape[1])).astype(np.uint8)\n",
    "    # print(img_mask)\n",
    "    img_mask[img_mask >= 127.5]=255\n",
    "    img_mask[img_mask <127.5]=0\n",
    "    result_img = Image.fromarray(img_mask)\n",
    "    c_img_id = img_id.split('/')[-1]\n",
    "    name, ext = os.path.splitext(c_img_id)\n",
    "    result_img.save('./result/' + name + '_mask_unet'+ext)\n",
    "    # print('./result/' + name + '_mask_'+ext)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unet_with_fine_tuning_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/killthekitten/kaggle-carvana-2017/blob/master/models.py\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.engine.topology import Input\n",
    "from keras.engine.training import Model\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.core import Activation, SpatialDropout2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from inception_resnet_v2 import InceptionResNetV2\n",
    "from mobile_net_fixed import MobileNet\n",
    "from resnet50_fixed import ResNet50\n",
    "# from params import args\n",
    "\n",
    "\n",
    "def conv_block_simple(prevlayer, filters, prefix, strides=(1, 1)):\n",
    "    conv = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", strides=strides,\n",
    "                  name=prefix + \"_conv\")(prevlayer)\n",
    "    conv = BatchNormalization(name=prefix + \"_bn\")(conv)\n",
    "    conv = Activation('relu', name=prefix + \"_activation\")(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "def conv_block_simple_no_bn(prevlayer, filters, prefix, strides=(1, 1)):\n",
    "    conv = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", strides=strides,\n",
    "                  name=prefix + \"_conv\")(prevlayer)\n",
    "    conv = Activation('relu', name=prefix + \"_activation\")(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Unet with Mobile net encoder\n",
    "Uses caffe preprocessing function\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_unet_resnet(input_shape):\n",
    "    resnet_base = ResNet50(input_shape=input_shape, include_top=False)\n",
    "    \"\"\"\n",
    "    if args.show_summary:\n",
    "        resnet_base.summary()\n",
    "    \"\"\"\n",
    "    for l in resnet_base.layers:\n",
    "        l.trainable = True\n",
    "    conv1 = resnet_base.get_layer(\"activation_1\").output\n",
    "    conv2 = resnet_base.get_layer(\"activation_10\").output\n",
    "    conv3 = resnet_base.get_layer(\"activation_22\").output\n",
    "    conv4 = resnet_base.get_layer(\"activation_40\").output\n",
    "    conv5 = resnet_base.get_layer(\"activation_49\").output\n",
    "\n",
    "    up6 = concatenate([UpSampling2D()(conv5), conv4], axis=-1)\n",
    "    conv6 = conv_block_simple(up6, 256, \"conv6_1\")\n",
    "    conv6 = conv_block_simple(conv6, 256, \"conv6_2\")\n",
    "\n",
    "    up7 = concatenate([UpSampling2D()(conv6), conv3], axis=-1)\n",
    "    conv7 = conv_block_simple(up7, 192, \"conv7_1\")\n",
    "    conv7 = conv_block_simple(conv7, 192, \"conv7_2\")\n",
    "\n",
    "    up8 = concatenate([UpSampling2D()(conv7), conv2], axis=-1)\n",
    "    conv8 = conv_block_simple(up8, 128, \"conv8_1\")\n",
    "    conv8 = conv_block_simple(conv8, 128, \"conv8_2\")\n",
    "\n",
    "    up9 = concatenate([UpSampling2D()(conv8), conv1], axis=-1)\n",
    "    conv9 = conv_block_simple(up9, 64, \"conv9_1\")\n",
    "    conv9 = conv_block_simple(conv9, 64, \"conv9_2\")\n",
    "\n",
    "    vgg = VGG16(input_shape=input_shape, input_tensor=resnet_base.input, include_top=False)\n",
    "    for l in vgg.layers:\n",
    "        l.trainable = False\n",
    "    vgg_first_conv = vgg.get_layer(\"block1_conv2\").output\n",
    "    up10 = concatenate([UpSampling2D()(conv9), resnet_base.input, vgg_first_conv], axis=-1)\n",
    "    conv10 = conv_block_simple(up10, 32, \"conv10_1\")\n",
    "    conv10 = conv_block_simple(conv10, 32, \"conv10_2\")\n",
    "    conv10 = SpatialDropout2D(0.2)(conv10)\n",
    "    x = Conv2D(1, (1, 1), activation=\"sigmoid\", name=\"prediction\")(conv10)\n",
    "    model = Model(resnet_base.input, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_simple_unet(input_shape):\n",
    "    img_input = Input(input_shape)\n",
    "    conv1 = conv_block_simple(img_input, 32, \"conv1_1\")\n",
    "    conv1 = conv_block_simple(conv1, 32, \"conv1_2\")\n",
    "    pool1 = MaxPooling2D((2, 2), strides=(2, 2), padding=\"same\", name=\"pool1\")(conv1)\n",
    "\n",
    "    conv2 = conv_block_simple(pool1, 64, \"conv2_1\")\n",
    "    conv2 = conv_block_simple(conv2, 64, \"conv2_2\")\n",
    "    pool2 = MaxPooling2D((2, 2), strides=(2, 2), padding=\"same\", name=\"pool2\")(conv2)\n",
    "\n",
    "    conv3 = conv_block_simple(pool2, 128, \"conv3_1\")\n",
    "    conv3 = conv_block_simple(conv3, 128, \"conv3_2\")\n",
    "    pool3 = MaxPooling2D((2, 2), strides=(2, 2), padding=\"same\", name=\"pool3\")(conv3)\n",
    "\n",
    "    conv4 = conv_block_simple(pool3, 256, \"conv4_1\")\n",
    "    conv4 = conv_block_simple(conv4, 256, \"conv4_2\")\n",
    "    conv4 = conv_block_simple(conv4, 256, \"conv4_3\")\n",
    "\n",
    "    up5 = concatenate([UpSampling2D()(conv4), conv3], axis=-1)\n",
    "    conv5 = conv_block_simple(up5, 128, \"conv5_1\")\n",
    "    conv5 = conv_block_simple(conv5, 128, \"conv5_2\")\n",
    "\n",
    "    up6 = concatenate([UpSampling2D()(conv5), conv2], axis=-1)\n",
    "    conv6 = conv_block_simple(up6, 64, \"conv6_1\")\n",
    "    conv6 = conv_block_simple(conv6, 64, \"conv6_2\")\n",
    "\n",
    "    up7 = concatenate([UpSampling2D()(conv6), conv1], axis=-1)\n",
    "    conv7 = conv_block_simple(up7, 32, \"conv7_1\")\n",
    "    conv7 = conv_block_simple(conv7, 32, \"conv7_2\")\n",
    "\n",
    "    conv7 = SpatialDropout2D(0.2)(conv7)\n",
    "\n",
    "    prediction = Conv2D(1, (1, 1), activation=\"sigmoid\", name=\"prediction\")(conv7)\n",
    "    model = Model(img_input, prediction)\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Unet with Mobile net encoder\n",
    "Uses the same preprocessing as in Inception, Xception etc. (imagenet_utils.preprocess_input with mode 'tf' in new Keras version)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_unet_mobilenet(input_shape):\n",
    "    base_model = MobileNet(include_top=False, input_shape=input_shape)\n",
    "\n",
    "    conv1 = base_model.get_layer('conv_pw_1_relu').output\n",
    "    conv2 = base_model.get_layer('conv_pw_3_relu').output\n",
    "    conv3 = base_model.get_layer('conv_pw_5_relu').output\n",
    "    conv4 = base_model.get_layer('conv_pw_11_relu').output\n",
    "    conv5 = base_model.get_layer('conv_pw_13_relu').output\n",
    "    up6 = concatenate([UpSampling2D()(conv5), conv4], axis=-1)\n",
    "    conv6 = conv_block_simple(up6, 256, \"conv6_1\")\n",
    "    conv6 = conv_block_simple(conv6, 256, \"conv6_2\")\n",
    "\n",
    "    up7 = concatenate([UpSampling2D()(conv6), conv3], axis=-1)\n",
    "    conv7 = conv_block_simple(up7, 256, \"conv7_1\")\n",
    "    conv7 = conv_block_simple(conv7, 256, \"conv7_2\")\n",
    "\n",
    "    up8 = concatenate([UpSampling2D()(conv7), conv2], axis=-1)\n",
    "    conv8 = conv_block_simple(up8, 192, \"conv8_1\")\n",
    "    conv8 = conv_block_simple(conv8, 128, \"conv8_2\")\n",
    "\n",
    "    up9 = concatenate([UpSampling2D()(conv8), conv1], axis=-1)\n",
    "    conv9 = conv_block_simple(up9, 96, \"conv9_1\")\n",
    "    conv9 = conv_block_simple(conv9, 64, \"conv9_2\")\n",
    "\n",
    "    up10 = concatenate([UpSampling2D()(conv9), base_model.input], axis=-1)\n",
    "    conv10 = conv_block_simple(up10, 48, \"conv10_1\")\n",
    "    conv10 = conv_block_simple(conv10, 32, \"conv10_2\")\n",
    "    conv10 = SpatialDropout2D(0.2)(conv10)\n",
    "    x = Conv2D(1, (1, 1), activation=\"sigmoid\", name=\"prediction\")(conv10)\n",
    "    model = Model(base_model.input, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Unet with Inception Resnet V2 encoder\n",
    "Uses the same preprocessing as in Inception, Xception etc. (imagenet_utils.preprocess_input with mode 'tf' in new Keras version)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_unet_inception_resnet_v2(input_shape):\n",
    "    base_model = InceptionResNetV2(include_top=False, input_shape=input_shape)\n",
    "    conv1 = base_model.get_layer('activation_3').output\n",
    "    conv2 = base_model.get_layer('activation_5').output\n",
    "    conv3 = base_model.get_layer('block35_10_ac').output\n",
    "    conv4 = base_model.get_layer('block17_20_ac').output\n",
    "    conv5 = base_model.get_layer('conv_7b_ac').output\n",
    "    up6 = concatenate([UpSampling2D()(conv5), conv4], axis=-1)\n",
    "    conv6 = conv_block_simple(up6, 256, \"conv6_1\")\n",
    "    conv6 = conv_block_simple(conv6, 256, \"conv6_2\")\n",
    "\n",
    "    up7 = concatenate([UpSampling2D()(conv6), conv3], axis=-1)\n",
    "    conv7 = conv_block_simple(up7, 256, \"conv7_1\")\n",
    "    conv7 = conv_block_simple(conv7, 256, \"conv7_2\")\n",
    "\n",
    "    up8 = concatenate([UpSampling2D()(conv7), conv2], axis=-1)\n",
    "    conv8 = conv_block_simple(up8, 128, \"conv8_1\")\n",
    "    conv8 = conv_block_simple(conv8, 128, \"conv8_2\")\n",
    "\n",
    "    up9 = concatenate([UpSampling2D()(conv8), conv1], axis=-1)\n",
    "    conv9 = conv_block_simple(up9, 64, \"conv9_1\")\n",
    "    conv9 = conv_block_simple(conv9, 64, \"conv9_2\")\n",
    "\n",
    "    up10 = concatenate([UpSampling2D()(conv9), base_model.input], axis=-1)\n",
    "    conv10 = conv_block_simple(up10, 48, \"conv10_1\")\n",
    "    conv10 = conv_block_simple(conv10, 32, \"conv10_2\")\n",
    "    conv10 = SpatialDropout2D(0.4)(conv10)\n",
    "    x = Conv2D(1, (1, 1), activation=\"sigmoid\", name=\"prediction\")(conv10)\n",
    "    model = Model(base_model.input, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_vgg_7conv(input_shape):\n",
    "    img_input = Input(input_shape)\n",
    "    vgg16_base = VGG16(input_tensor=img_input, include_top=False)\n",
    "    for l in vgg16_base.layers:\n",
    "        l.trainable = True\n",
    "    conv1 = vgg16_base.get_layer(\"block1_conv2\").output\n",
    "    conv2 = vgg16_base.get_layer(\"block2_conv2\").output\n",
    "    conv3 = vgg16_base.get_layer(\"block3_conv3\").output\n",
    "    pool3 = vgg16_base.get_layer(\"block3_pool\").output\n",
    "\n",
    "    conv4 = Conv2D(384, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\",\n",
    "                   name=\"block4_conv1\")(pool3)\n",
    "    conv4 = Conv2D(384, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\",\n",
    "                   name=\"block4_conv2\")(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\",\n",
    "                   name=\"block5_conv1\")(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\",\n",
    "                   name=\"block5_conv2\")(conv5)\n",
    "    pool5 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(conv5)\n",
    "\n",
    "    conv6 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\",\n",
    "                   name=\"block6_conv1\")(pool5)\n",
    "    conv6 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\",\n",
    "                   name=\"block6_conv2\")(conv6)\n",
    "    pool6 = MaxPooling2D((2, 2), strides=(2, 2), name='block6_pool')(conv6)\n",
    "\n",
    "    conv7 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\",\n",
    "                   name=\"block7_conv1\")(pool6)\n",
    "    conv7 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\",\n",
    "                   name=\"block7_conv2\")(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                                       strides=(2, 2), padding='same')(conv7), conv6], axis=3)\n",
    "    conv8 = Conv2D(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                                       strides=(2, 2), padding='same')(conv8), conv5], axis=3)\n",
    "    conv9 = Conv2D(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up9)\n",
    "\n",
    "    up10 = concatenate([Conv2DTranspose(192, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                                        strides=(2, 2), padding='same')(conv9), conv4], axis=3)\n",
    "    conv10 = Conv2D(192, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up10)\n",
    "\n",
    "    up11 = concatenate([Conv2DTranspose(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                                        strides=(2, 2), padding='same')(conv10), conv3], axis=3)\n",
    "    conv11 = Conv2D(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up11)\n",
    "\n",
    "    up12 = concatenate([Conv2DTranspose(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                                        strides=(2, 2), padding='same')(conv11), conv2], axis=3)\n",
    "    conv12 = Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up12)\n",
    "\n",
    "    up13 = concatenate([Conv2DTranspose(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                                        strides=(2, 2), padding='same')(conv12), conv1], axis=3)\n",
    "    conv13 = Conv2D(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up13)\n",
    "\n",
    "    conv13 = Conv2D(1, (1, 1))(conv13)\n",
    "    conv13 = Activation(\"sigmoid\")(conv13)\n",
    "    model = Model(img_input, conv13)\n",
    "    return model\n",
    "\n",
    "\n",
    "def chose_model(input_shape, network):\n",
    "    if network == 'resnet50':\n",
    "        return get_unet_resnet(input_shape)\n",
    "    if network == 'inception_resnet_v2':\n",
    "        return get_unet_inception_resnet_v2(input_shape)\n",
    "    elif network == 'mobilenet':\n",
    "        return get_unet_mobilenet(input_shape)\n",
    "    elif network == 'vgg':\n",
    "        return get_vgg_7conv(input_shape)\n",
    "    elif network == 'simple_unet':\n",
    "        return get_simple_unet(input_shape)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
